import logging
import os
import time
from typing import List, Dict, Any, Optional
from datetime import datetime, date
from sqlalchemy import func
from sqlalchemy.dialects.postgresql import insert as pg_insert

from ...core.database import get_postgres_db
from ...models.asset import (
    RealtimeQuote, RealtimeQuoteTimeDelay, StockProfile, ETFInfo, 
    CryptoData, StockFinancial, StockAnalystEstimate, WorldAssetsRanking,
    CryptoMetric
)

logger = logging.getLogger(__name__)

class DataRepository:
    """ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‘ì—…ì„ ì „ë‹´í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, validator):
        self.validator = validator
        self.bulk_upsert_enabled = os.getenv("BULK_UPSERT_ENABLED", "true").lower() == "true"
        self.batch_size = int(os.getenv("BULK_BATCH_SIZE", "1000"))

    def _sanitize_number(self, val, min_abs=0.0, max_abs=1e9, digits=8):
        try:
            if val is None:
                return None
            f = float(val)
            if not (f == f) or f == float('inf') or f == float('-inf'):
                return None
            if abs(f) < min_abs:
                f = 0.0
            if abs(f) > max_abs:
                return None
            return round(f, digits)
        except Exception:
            return None

    def _get_time_window(self, timestamp: datetime, interval_minutes: int = 15) -> datetime:
        """ì§€ì •ëœ ë¶„ ë‹¨ìœ„ë¡œ ì‹œê°„ ìœˆë„ìš° ê³„ì‚°"""
        try:
            minute = (timestamp.minute // interval_minutes) * interval_minutes
            return timestamp.replace(minute=minute, second=0, microsecond=0)
        except Exception:
            return timestamp

    async def bulk_save_realtime_quotes(self, records: List[Dict[str, Any]]) -> bool:
        """ì‹¤ì‹œê°„ ì¸ìš© ë°ì´í„° ì¼ê´„ ì €ì¥"""
        if not records:
            logger.warning("âš ï¸ ì €ì¥í•  ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        logger.debug(f"ğŸ” ê²€ì¦ ì‹œì‘: {len(records)}ê°œ ë ˆì½”ë“œ")
        # ë°ì´í„° ê²€ì¦
        validated_records = []
        for record in records:
            if self.validator.validate_realtime_quote(record):
                validated_records.append(record)

        if not validated_records:
            logger.warning(f"ğŸš¨ ê²€ì¦ì„ í†µê³¼í•œ ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤. (ì…ë ¥: {len(records)}ê°œ)")
            return False
        
        logger.debug(f"âœ… ê²€ì¦ í†µê³¼: {len(validated_records)}/{len(records)}ê°œ")

        pg_db = next(get_postgres_db())
        try:
            batch_size = self.batch_size if self.bulk_upsert_enabled else 1
            success_count = 0

            for start_idx in range(0, len(validated_records), batch_size):
                batch = validated_records[start_idx:start_idx + batch_size]
                if not batch:
                    continue

                # ì‹¤ì‹œê°„ í…Œì´ë¸”ìš© ë°ì´í„°
                dedup_rt = {}
                rt_allowed_keys = {'asset_id', 'timestamp_utc', 'price', 'volume', 'change_amount', 'change_percent', 'data_source'}
                for rec in batch:
                    r = {k: v for k, v in rec.items() if k in rt_allowed_keys}
                    r['price'] = self._sanitize_number(rec.get('price'))
                    r['volume'] = self._sanitize_number(rec.get('volume'))
                    r['change_amount'] = self._sanitize_number(rec.get('change_amount'))
                    r['change_percent'] = self._sanitize_number(rec.get('change_percent'))
                    if r['price'] is None:
                        continue
                    # Ensure required fields
                    if 'asset_id' not in r or 'timestamp_utc' not in r or 'data_source' not in r:
                        continue
                    dedup_rt[r['asset_id']] = r
                realtime_rows = list(dedup_rt.values())

                # ì§€ì—° í…Œì´ë¸”ìš© ë°ì´í„°
                delay_dedup = {}
                delay_allowed_keys = {'asset_id', 'timestamp_utc', 'price', 'volume', 'change_amount', 'change_percent', 'data_source', 'data_interval'}
                for rec in batch:
                    d = {k: v for k, v in rec.items() if k in delay_allowed_keys}
                    tw = self._get_time_window(rec['timestamp_utc'])
                    d['timestamp_utc'] = tw
                    d['data_interval'] = "15m" # TODO: Make configurable
                    d['price'] = self._sanitize_number(rec.get('price'))
                    d['volume'] = self._sanitize_number(rec.get('volume'))
                    d['change_amount'] = self._sanitize_number(rec.get('change_amount'))
                    d['change_percent'] = self._sanitize_number(rec.get('change_percent'))
                    
                    # Missing keys from filtering might need to be re-added if they were derived or renamed
                    # But here 'rec' has the source data.
                    # Wait, 'd' is filtered from 'rec'. 'rec' has 'ticker' etc.
                    # We need to make sure 'd' has what we need.
                    if 'asset_id' not in d: d['asset_id'] = rec.get('asset_id')
                    if 'data_source' not in d: d['data_source'] = rec.get('data_source')
                    
                    if d['price'] is None:
                        continue
                    key = (d['asset_id'], d['timestamp_utc'], d['data_source'])
                    delay_dedup[key] = d
                delay_rows = list(delay_dedup.values())

                try:
                    # ì‹¤ì‹œê°„ í…Œì´ë¸” UPSERT
                    if realtime_rows:
                        stmt = pg_insert(RealtimeQuote).values(realtime_rows)
                        stmt = stmt.on_conflict_do_update(
                            index_elements=['asset_id'],
                            set_={
                                'timestamp_utc': stmt.excluded.timestamp_utc,
                                'price': stmt.excluded.price,
                                'volume': stmt.excluded.volume,
                                'change_amount': stmt.excluded.change_amount,
                                'change_percent': stmt.excluded.change_percent,
                                'data_source': stmt.excluded.data_source,
                                'updated_at': func.now()
                            }
                        )
                        pg_db.execute(stmt)

                    # ì§€ì—° í…Œì´ë¸” UPSERT
                    if delay_rows:
                        stmt = pg_insert(RealtimeQuoteTimeDelay).values(delay_rows)
                        stmt = stmt.on_conflict_do_update(
                            index_elements=['asset_id', 'timestamp_utc', 'data_source'],
                            set_={
                                'price': stmt.excluded.price,
                                'volume': stmt.excluded.volume,
                                'change_amount': stmt.excluded.change_amount,
                                'change_percent': stmt.excluded.change_percent,
                                'updated_at': func.now()
                            }
                        )
                        pg_db.execute(stmt)

                    pg_db.commit()
                    success_count += len(batch)
                    logger.debug(f"ğŸ’¾ ë°°ì¹˜ ì €ì¥ ì„±ê³µ: {len(batch)}ê°œ (ì‹¤ì‹œê°„: {len(realtime_rows)}, ì§€ì—°: {len(delay_rows)})")
                except Exception as e:
                    pg_db.rollback()
                    logger.error(f"âŒ Bulk upsert ì‹¤íŒ¨: {e}", exc_info=True)
                    # TODO: Implement fallback/retry logic if needed

            logger.info(f"ğŸ’¾ ì´ ì €ì¥ ì™„ë£Œ: {success_count}/{len(validated_records)}ê°œ")
            return success_count > 0
        finally:
            pg_db.close()

    async def save_stock_profile(self, items: List[Dict[str, Any]]) -> bool:
        if not items:
            return True

        pg_db = next(get_postgres_db())
        try:
            for item in items:
                try:
                    asset_id = item.get("asset_id") or item.get("assetId")
                    data = item.get("data") if "data" in item else item
                    if not asset_id or not isinstance(data, dict):
                        continue

                    # ë°ì´í„° ë§¤í•‘ (ê°„ì†Œí™”ë¨, í•„ìš”ì‹œ í•„ë“œ ì¶”ê°€)
                    pg_data = {
                        'asset_id': asset_id,
                        'company_name': data.get("name") or data.get("company_name"),
                        'description_en': data.get("description_en") or data.get("description"),
                        'sector': data.get("sector"),
                        'industry': data.get("industry"),
                        'market_cap': data.get("market_cap"),
                        # ... ê¸°íƒ€ í•„ë“œë“¤ ...
                    }
                    # None ì œê±°
                    pg_data = {k: v for k, v in pg_data.items() if v is not None}

                    stmt = pg_insert(StockProfile).values(**pg_data)
                    stmt = stmt.on_conflict_do_update(
                        index_elements=['asset_id'],
                        set_={k: getattr(stmt.excluded, k) for k in pg_data.keys() if k != 'asset_id'}
                    )
                    # updated_at ì¶”ê°€
                    if 'updated_at' in StockProfile.__table__.columns:
                         stmt = stmt.on_conflict_do_update(
                            index_elements=['asset_id'],
                            set_={**{k: getattr(stmt.excluded, k) for k in pg_data.keys() if k != 'asset_id'}, 'updated_at': func.now()}
                        )

                    pg_db.execute(stmt)
                except Exception as e:
                    logger.warning(f"ê°œë³„ ì£¼ì‹ í”„ë¡œí•„ ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            pg_db.commit()
            return True
        except Exception as e:
            pg_db.rollback()
            logger.error(f"ì£¼ì‹ í”„ë¡œí•„ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
        finally:
            pg_db.close()

    async def save_crypto_data(self, items: List[Dict[str, Any]]) -> bool:
        if not items:
            return True
            
        pg_db = next(get_postgres_db())
        try:
            saved_count = 0
            for item in items:
                try:
                    asset_id = item.get('asset_id')
                    if not asset_id:
                        continue
                    
                    crypto_data_dict = {
                        'asset_id': asset_id,
                        'symbol': item.get('symbol', ''),
                        'name': item.get('name', ''),
                        'price': item.get('price'),
                        'current_price': item.get('price'),  # priceì™€ current_price ë™ê¸°í™”
                        'market_cap': item.get('market_cap'),
                        'circulating_supply': item.get('circulating_supply'),
                        'total_supply': item.get('total_supply'),
                        'max_supply': item.get('max_supply'),
                        'volume_24h': item.get('volume_24h'),
                        'percent_change_1h': item.get('percent_change_1h'),
                        'percent_change_24h': item.get('percent_change_24h'),
                        'percent_change_7d': item.get('percent_change_7d'),
                        'percent_change_30d': item.get('percent_change_30d'),
                        'cmc_rank': item.get('rank'),
                        'category': item.get('category'),
                        'description': item.get('description'),
                        'logo_url': item.get('logo_url'),
                        'website_url': item.get('website_url'),
                        'slug': item.get('slug'),
                        'date_added': item.get('date_added'),
                        'platform': item.get('platform'),
                        'explorer': item.get('explorer'),
                        'source_code': item.get('source_code'),
                        'tags': item.get('tags'),
                        'is_active': True
                    }
                    crypto_data_dict = {k: v for k, v in crypto_data_dict.items() if v is not None}
                    

                    # logo_url: ì´ë¯¸ ë¡œì»¬ ê²½ë¡œ('/images/')ë¡œ ì„¤ì •ëœ ê²½ìš° ë®ì–´ì“°ì§€ ì•ŠìŒ
                    stmt = pg_insert(CryptoData).values(**crypto_data_dict)
                    set_dict = {k: getattr(stmt.excluded, k) for k in crypto_data_dict.keys() if k != 'asset_id'}
                    
                    # logo_urlì— ëŒ€í•œ ì¡°ê±´ë¶€ ì—…ë°ì´íŠ¸ ë¡œì§ ì ìš©
                    if 'logo_url' in set_dict:
                        from sqlalchemy import case, literal
                        # ê¸°ì¡´ ê°’ì´ '/images/%'ë¡œ ì‹œì‘í•˜ë©´(ë¡œì»¬ ì•„ì´ì½˜), ê¸°ì¡´ ê°’ ìœ ì§€. ì•„ë‹ˆë©´ ìƒˆë¡œìš´ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                        set_dict['logo_url'] = case(
                            (CryptoData.logo_url.like('/images/%'), CryptoData.logo_url),
                            else_=stmt.excluded.logo_url
                        )

                    stmt = stmt.on_conflict_do_update(
                        index_elements=['asset_id'],
                        set_={
                            **set_dict,
                            'last_updated': func.now()
                        }
                    )
                    pg_db.execute(stmt)
                    saved_count += 1
                except Exception as e:
                    logger.error(f"crypto_data ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            pg_db.commit()
            return saved_count > 0
        except Exception as e:
            pg_db.rollback()
            logger.error(f"crypto_data ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
        finally:
            pg_db.close()

    async def save_stock_financials(self, items: List[Dict[str, Any]]) -> bool:
        """ì£¼ì‹ ì¬ë¬´ ë°ì´í„° ì €ì¥"""
        if not items:
            return True

        pg_db = next(get_postgres_db())
        try:
            from ...models.asset import StockFinancial
            
            for item in items:
                try:
                    asset_id = item.get("asset_id") or item.get("assetId")
                    data = item.get("data") if isinstance(item, dict) and "data" in item else item
                    if not asset_id or not isinstance(data, dict):
                        continue

                    # í•„ë“œ ë§¤í•‘ (ê°„ì†Œí™”)
                    pg_data = {
                        'asset_id': asset_id,
                        'snapshot_date': data.get('snapshot_date') or data.get('date'),
                        'currency': data.get('currency'),
                        'market_cap': data.get('market_cap'),
                        'ebitda': data.get('ebitda'),
                        'pe_ratio': data.get('pe_ratio'),
                        # ... í•„ìš”í•œ í•„ë“œ ì¶”ê°€ ...
                    }
                    pg_data = {k: v for k, v in pg_data.items() if v is not None}

                    stmt = pg_insert(StockFinancial).values(**pg_data)
                    stmt = stmt.on_conflict_do_update(
                        index_elements=['asset_id'],
                        set_={k: getattr(stmt.excluded, k) for k in pg_data.keys() if k != 'asset_id'}
                    )
                    pg_db.execute(stmt)
                except Exception as e:
                    logger.warning(f"ê°œë³„ ì£¼ì‹ ì¬ë¬´ ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue

            pg_db.commit()
            return True
        except Exception as e:
            pg_db.rollback()
            logger.error(f"ì£¼ì‹ ì¬ë¬´ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
        finally:
            pg_db.close()

    async def save_stock_estimate(self, items: List[Dict[str, Any]]) -> bool:
        """ì£¼ì‹ ì¶”ì •ì¹˜ ë°ì´í„° ì €ì¥"""
        if not items:
            return True

        pg_db = next(get_postgres_db())
        try:
            from ...models.asset import StockAnalystEstimate
            
            for item in items:
                try:
                    asset_id = item.get("asset_id")
                    data = item.get("data") if "data" in item else item
                    if not asset_id:
                        continue
                    
                    # fiscal_date íŒŒì‹± ë“± ë¡œì§ í•„ìš”
                    fiscal_date = data.get("fiscal_date")
                    if not fiscal_date:
                        continue

                    pg_data = {
                        'asset_id': asset_id,
                        'fiscal_date': fiscal_date,
                        'revenue_avg': data.get('revenue_avg'),
                        # ...
                    }
                    pg_data = {k: v for k, v in pg_data.items() if v is not None}

                    stmt = pg_insert(StockAnalystEstimate).values(**pg_data)
                    stmt = stmt.on_conflict_do_update(
                        index_elements=['asset_id', 'fiscal_date'],
                        set_={k: getattr(stmt.excluded, k) for k in pg_data.keys() if k not in ['asset_id', 'fiscal_date']}
                    )
                    pg_db.execute(stmt)
                except Exception as e:
                    continue
            
            pg_db.commit()
            return True
        except Exception as e:
            pg_db.rollback()
            return False
        finally:
            pg_db.close()

    async def save_ohlcv_data(self, items: List[Dict[str, Any]], metadata: Dict[str, Any] = None) -> bool:
        """OHLCV ë°ì´í„° ì €ì¥ - ì¼ë´‰ê³¼ ì¸íŠ¸ë¼ë°ì´ ë°ì´í„°ë¥¼ ì ì ˆí•œ í…Œì´ë¸”ì— ë¶„ë¦¬ ì €ì¥"""
        if not items:
            return True
        
        if metadata is None:
            metadata = {}
            
        pg_db = next(get_postgres_db())
        try:
            from ...models.asset import OHLCVData, OHLCVIntradayData
            
            daily_items = []
            intraday_items = []
            
            # metadataì—ì„œ asset_id ê°€ì ¸ì˜¤ê¸° (Collectorê°€ ì—¬ê¸°ì— ë„£ìŒ)
            meta_asset_id = metadata.get('asset_id')
            meta_interval = metadata.get('interval')
            
            for item in items:
                # ë°ì´í„° ê°„ê²© ê²°ì • ë¡œì§
                interval = item.get('interval') or item.get('data_interval') or meta_interval
                if not interval:
                    # ë©”íƒ€ë°ì´í„°ë‚˜ ë¹ˆë„ ì •ë³´ë¡œ ì¶”ë¡ 
                    freq = metadata.get('frequency')
                    if freq:
                        if freq.lower() in ['daily', 'd', '1d']:
                            interval = '1d'
                        elif freq.lower() in ['weekly', 'w', '1w']:
                            interval = '1w'
                        elif freq.lower() in ['monthly', 'm', '1m']:
                            interval = '1M'
                        else:
                            interval = '1d' # Default to daily
                    else:
                         interval = '1d'

                # asset_id: itemì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ metadataì—ì„œ ê°€ì ¸ì˜´
                asset_id = item.get('asset_id') or meta_asset_id

                # ë°ì´í„° ì •ì œ
                pg_data = {
                    'asset_id': asset_id,
                    'timestamp_utc': item.get('timestamp_utc') or item.get('date'),
                    'open_price': self._sanitize_number(item.get('open_price') or item.get('open')),
                    'high_price': self._sanitize_number(item.get('high_price') or item.get('high')),
                    'low_price': self._sanitize_number(item.get('low_price') or item.get('low')),
                    'close_price': self._sanitize_number(item.get('close_price') or item.get('close')),
                    'volume': self._sanitize_number(item.get('volume')),
                    'data_interval': interval
                }
                
                if not pg_data['asset_id'] or not pg_data['timestamp_utc']:
                    continue
                    
                if interval in ['1d', '1w', '1M']:
                    daily_items.append(pg_data)
                else:
                    intraday_items.append(pg_data)

            # ì¼ë´‰ ë°ì´í„° ì €ì¥
            if daily_items:
                try:
                    logger.debug(f"ğŸ’¾ ì¼ë´‰ ë°ì´í„° ì €ì¥ ì‹œë„: {len(daily_items)}ê±´")
                    stmt = pg_insert(OHLCVData).values(daily_items)
                    # asset_id, timestamp_utc, data_interval ì¡°í•©ì´ unique constraintì¼ ê°€ëŠ¥ì„± ê³ ë ¤
                    # unique constraintê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ë§Œ, ê·¸ ê²½ìš°ì—ë„ ì²˜ë¦¬
                    try:
                        stmt = stmt.on_conflict_do_update(
                            index_elements=['asset_id', 'timestamp_utc', 'data_interval'],
                            set_={
                                'open_price': stmt.excluded.open_price,
                                'high_price': stmt.excluded.high_price,
                                'low_price': stmt.excluded.low_price,
                                'close_price': stmt.excluded.close_price,
                                'volume': stmt.excluded.volume,
                                'change_percent': stmt.excluded.change_percent,
                            }
                        )
                    except Exception:
                        # unique constraintê°€ ë‹¤ë¥¸ ì¡°í•©ì´ê±°ë‚˜ ì—†ëŠ” ê²½ìš°, ì¼ë°˜ insert ì‹œë„
                        pass
                    pg_db.execute(stmt)
                    logger.debug(f"âœ… ì¼ë´‰ ë°ì´í„° ì €ì¥ ì„±ê³µ: {len(daily_items)}ê±´")
                except Exception as e:
                    # ì¤‘ë³µ ì—ëŸ¬ì¸ ê²½ìš° ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                    if 'duplicate key' in str(e).lower() or 'unique constraint' in str(e).lower():
                        logger.warning(f"âš ï¸ ì¼ë´‰ ë°ì´í„° ì¤‘ë³µ ë¬´ì‹œ: {len(daily_items)}ê±´")
                    else:
                        logger.error(f"âŒ ì¼ë´‰ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
                        raise

            # ì¸íŠ¸ë¼ë°ì´ ë°ì´í„° ì €ì¥
            if intraday_items:
                try:
                    logger.debug(f"ğŸ’¾ ì¸íŠ¸ë¼ë°ì´ ë°ì´í„° ì €ì¥ ì‹œë„: {len(intraday_items)}ê±´")
                    stmt = pg_insert(OHLCVIntradayData).values(intraday_items)
                    # asset_id, timestamp_utc, data_interval ì¡°í•©ì´ unique constraintì¼ ê°€ëŠ¥ì„± ê³ ë ¤
                    try:
                        stmt = stmt.on_conflict_do_update(
                            index_elements=['asset_id', 'timestamp_utc', 'data_interval'],
                            set_={
                                'open_price': stmt.excluded.open_price,
                                'high_price': stmt.excluded.high_price,
                                'low_price': stmt.excluded.low_price,
                                'close_price': stmt.excluded.close_price,
                                'volume': stmt.excluded.volume,
                                'change_percent': stmt.excluded.change_percent,
                            }
                        )
                    except Exception:
                        # unique constraintê°€ ë‹¤ë¥¸ ì¡°í•©ì´ê±°ë‚˜ ì—†ëŠ” ê²½ìš°, ì¼ë°˜ insert ì‹œë„
                        pass
                    pg_db.execute(stmt)
                    logger.debug(f"âœ… ì¸íŠ¸ë¼ë°ì´ ë°ì´í„° ì €ì¥ ì„±ê³µ: {len(intraday_items)}ê±´")
                except Exception as e:
                    # ì¤‘ë³µ ì—ëŸ¬ì¸ ê²½ìš° ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                    if 'duplicate key' in str(e).lower() or 'unique constraint' in str(e).lower():
                        logger.warning(f"âš ï¸ ì¸íŠ¸ë¼ë°ì´ ë°ì´í„° ì¤‘ë³µ ë¬´ì‹œ: {len(intraday_items)}ê±´")
                    else:
                        logger.error(f"âŒ ì¸íŠ¸ë¼ë°ì´ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
                        raise

            pg_db.commit()
            total_saved = len(daily_items) + len(intraday_items)
            if total_saved > 0:
                logger.info(f"âœ… OHLCV ì €ì¥ ì™„ë£Œ: daily={len(daily_items)}, intraday={len(intraday_items)}")
            return True
            
        except Exception as e:
            pg_db.rollback()
            logger.error(f"OHLCV ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
        finally:
            pg_db.close()

    async def save_world_assets_ranking(self, items: List[Dict[str, Any]], metadata: Dict[str, Any]) -> bool:
        """ì„¸ê³„ ìì‚° ë­í‚¹ ë°ì´í„° ì €ì¥"""
        if not items:
            return True
        pg_db = next(get_postgres_db())
        try:
            from ...models.asset import WorldAssetsRanking
            
            saved_count = 0
            for item in items:
                try:
                    ticker = item.get('ticker')
                    if not ticker:
                        continue
                        
                    ranking_date = metadata.get('collection_date', datetime.now().date())
                    data_source = metadata.get('data_source', 'unknown')
                    
                    pg_data = {
                        'rank': item.get('rank'),
                        'name': item.get('name'),
                        'ticker': ticker,
                        'market_cap_usd': item.get('market_cap_usd'),
                        'price_usd': item.get('price_usd'),
                        'daily_change_percent': item.get('daily_change_percent'),
                        'ranking_date': ranking_date,
                        'data_source': data_source,
                    }
                    
                    stmt = pg_insert(WorldAssetsRanking).values(**pg_data)
                    stmt = stmt.on_conflict_do_update(
                        index_elements=['ranking_date', 'ticker', 'data_source'],
                        set_={
                            'rank': stmt.excluded.rank,
                            'name': stmt.excluded.name,
                            'market_cap_usd': stmt.excluded.market_cap_usd,
                            'price_usd': stmt.excluded.price_usd,
                            'daily_change_percent': stmt.excluded.daily_change_percent,
                            'last_updated': func.now()
                        }
                    )
                    pg_db.execute(stmt)
                    saved_count += 1
                except Exception as e:
                    logger.warning(f"WorldAssetsRanking ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            pg_db.commit()
            return saved_count > 0
        except Exception as e:
            pg_db.rollback()
            logger.error(f"WorldAssetsRanking ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
        finally:
            pg_db.close()

    async def save_etf_info(self, items: List[Dict[str, Any]]) -> bool:
        """ETF ì •ë³´ ì €ì¥"""
        if not items:
            return True
            
        pg_db = next(get_postgres_db())
        try:
            from ...models.asset import ETFInfo
            
            saved_count = 0
            for item in items:
                try:
                    asset_id = item.get('asset_id')
                    if not asset_id:
                        continue
                    
                    data = item.get('data') if 'data' in item else item
                    
                    pg_data = {
                        'asset_id': asset_id,
                        'snapshot_date': data.get('snapshot_date') or date.today(),
                        'net_assets': self._sanitize_number(data.get('net_assets'), max_abs=1e18),
                        'net_expense_ratio': self._sanitize_number(data.get('net_expense_ratio')),
                        'portfolio_turnover': self._sanitize_number(data.get('portfolio_turnover')),
                        'dividend_yield': self._sanitize_number(data.get('dividend_yield')),
                        'inception_date': data.get('inception_date'),
                        'leveraged': data.get('leveraged'),
                        'sectors': data.get('sectors'),
                        'holdings': data.get('holdings'),
                    }
                    pg_data = {k: v for k, v in pg_data.items() if v is not None}
                    
                    stmt = pg_insert(ETFInfo).values(**pg_data)
                    stmt = stmt.on_conflict_do_update(
                        index_elements=['asset_id'],
                        set_={k: getattr(stmt.excluded, k) for k in pg_data.keys() if k != 'asset_id'}
                    )
                    pg_db.execute(stmt)
                    saved_count += 1
                except Exception as e:
                    logger.warning(f"ETF ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            pg_db.commit()
            return saved_count > 0
        except Exception as e:
            pg_db.rollback()
            logger.error(f"ETF ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
        finally:
            pg_db.close()

    async def save_macrotrends_financials(self, items: List[Dict[str, Any]]) -> bool:
        """Macrotrends ì¬ë¬´ ë°ì´í„° ì €ì¥"""
        if not items:
            return True
            
        pg_db = next(get_postgres_db())
        try:
            from ...models.asset import MacrotrendsFinancial
            
            saved_count = 0
            for item in items:
                try:
                    # camelCaseì™€ snake_case ëª¨ë‘ ì§€ì›
                    asset_id = item.get('asset_id') or item.get('assetId')
                    section = item.get('section')
                    field_name = item.get('field_name') or item.get('fieldName')
                    snapshot_date = item.get('snapshot_date') or item.get('snapshotDate')
                    
                    if not all([asset_id, section, field_name, snapshot_date]):
                        continue
                    
                    pg_data = {
                        'asset_id': asset_id,
                        'section': section,
                        'field_name': field_name,
                        'snapshot_date': snapshot_date,
                        'value_numeric': self._sanitize_number(
                            item.get('value_numeric') or item.get('valueNumeric'), 
                            max_abs=1e18
                        ),
                        'value_text': item.get('value_text') or item.get('valueText'),
                        'unit': item.get('unit'),
                        'currency': item.get('currency'),
                        'source_url': item.get('source_url') or item.get('sourceUrl'),
                    }
                    pg_data = {k: v for k, v in pg_data.items() if v is not None}
                    
                    stmt = pg_insert(MacrotrendsFinancial).values(**pg_data)
                    stmt = stmt.on_conflict_do_update(
                        index_elements=['asset_id', 'section', 'field_name', 'snapshot_date'],
                        set_={k: getattr(stmt.excluded, k) for k in pg_data.keys() 
                              if k not in ['asset_id', 'section', 'field_name', 'snapshot_date']}
                    )
                    pg_db.execute(stmt)
                    saved_count += 1
                except Exception as e:
                    logger.warning(f"Macrotrends ì¬ë¬´ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            pg_db.commit()
            logger.info(f"âœ… macrotrends_financials ì €ì¥ ì™„ë£Œ: {saved_count}ê±´")
            return saved_count > 0
        except Exception as e:
            pg_db.rollback()
            logger.error(f"Macrotrends ì¬ë¬´ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
        finally:
            pg_db.close()

    async def save_onchain_metrics(self, items: List[Dict[str, Any]]) -> bool:
        """ì˜¨ì²´ì¸ ë©”íŠ¸ë¦­ ë°ì´í„° ì €ì¥ (Bulk UPSERT ìµœì í™” ë²„ì „)"""
        if not items:
            return True
        
        pg_db = next(get_postgres_db())
        try:
            # Debug: Check known columns
            # logger.info(f"DEBUG: CryptoMetric columns: {CryptoMetric.__table__.columns.keys()}")

            # 1. ìˆ˜ì§‘ ê°€ëŠ¥í•œ ëª¨ë“  í•„ë“œ ì •ì˜ (Group A + Group B ì „ì²´)
            all_metric_fields = [
                # Group A (í™€ìˆ˜ì¼)
                'mvrv_z_score', 'mvrv', 'nupl', 'sopr', 'realized_price',
                'sth_realized_price', 'lth_mvrv', 'sth_mvrv', 'lth_nupl',
                'sth_nupl', 'aviv', 'true_market_mean', 'terminal_price',
                'delta_price_usd', 'market_cap',
                # Group B (ì§ìˆ˜ì¼)
                'hashrate', 'difficulty', 'thermo_cap', 'puell_multiple',
                'reserve_risk', 'rhodl_ratio', 'nvts', 'nrpl_usd',
                'utxos_in_profit_pct', 'utxos_in_loss_pct', 'realized_cap',
                'etf_btc_flow', 'etf_btc_total', 'hodl_waves_supply', 'cdd_90dma',
                'hodl_age_distribution',
            ]
            
            # 2. ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ë° ì •ì œ
            valid_pg_data_list = []
            for item in items:
                asset_id = item.get('asset_id')
                ts = item.get('timestamp_utc')
                if not asset_id or not ts: continue
                
                pg_data = {'asset_id': asset_id, 'timestamp_utc': ts}
                has_metric = False
                for field in all_metric_fields:
                    val = item.get(field)
                    if val is not None:
                        pg_data[field] = val if field in ('hodl_age_distribution', 'open_interest_futures') else self._sanitize_number(val)
                        has_metric = True
                if has_metric:
                    valid_pg_data_list.append(pg_data)

            if not valid_pg_data_list:
                return True

            # 3. ë°°ì¹˜ ì²˜ë¦¬ (ëŒ€ëŸ‰ ë°ì´í„°ì¸ ê²½ìš° 1000ê°œì”© ëŠì–´ì„œ ì²˜ë¦¬)
            batch_size = 1000
            for i in range(0, len(valid_pg_data_list), batch_size):
                batch = valid_pg_data_list[i : i + batch_size]
                
                stmt = pg_insert(CryptoMetric).values(batch)
                
                # ì—…ë°ì´íŠ¸í•  í•„ë“œ ê²°ì • (ë°°ì¹˜ ë‚´ì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  ë©”íŠ¸ë¦­ í•„ë“œ)
                update_fields = set()
                for d in batch:
                    for k in d.keys():
                        if k not in ('asset_id', 'timestamp_utc'):
                            update_fields.add(k)
                
                update_dict = {k: getattr(stmt.excluded, k) for k in update_fields}
                update_dict['updated_at'] = func.now()
                
                stmt = stmt.on_conflict_do_update(
                    index_elements=['asset_id', 'timestamp_utc'],
                    set_=update_dict
                )
                
                pg_db.execute(stmt)
            
            pg_db.commit()
            logger.info(f"âœ… ì˜¨ì²´ì¸ ë©”íŠ¸ë¦­ ì €ì¥ ì™„ë£Œ: {len(valid_pg_data_list)}ê±´ (Bulk UPSERT)")
            return True
            
        except Exception as e:
            pg_db.rollback()
            logger.error(f"ì˜¨ì²´ì¸ ë©”íŠ¸ë¦­ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
            return False
        finally:
            pg_db.close()
