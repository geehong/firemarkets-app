"""
WebSocket Broadcaster Service
- Connects to Redis Pub/Sub.
- Listens for real-time quote messages.
- Forwards messages to the main backend service via an internal Socket.IO connection.
"""

import asyncio
import json
import logging
import os
import signal
import sys
import time
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, Optional, List

import redis.asyncio as redis
from redis import exceptions
import socketio

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(project_root))

from app.core.config import GLOBAL_APP_CONFIGS, load_and_set_global_configs
from app.utils.helpers import safe_float

# ë¡œê¹… ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ìƒì„¸ ë¡œê·¸ ì œì–´)
verbose = os.getenv("BROADCASTER_VERBOSE", "false").lower() == "true"
log_level = logging.DEBUG if verbose else logging.INFO

logging.basicConfig(level=log_level, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")

import sys
_sh = logging.StreamHandler(sys.stdout)
_sh.setLevel(log_level)
_sh.setFormatter(logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s"))
root_logger = logging.getLogger()
root_logger.handlers = []
root_logger.addHandler(_sh)
root_logger.setLevel(log_level)

logger = logging.getLogger("WebSocketBroadcaster")
logger.setLevel(log_level)

# ì „ì—­ ì„¤ì • ë¡œë“œ
try:
    load_and_set_global_configs()
    logger.info("âœ… Global configurations loaded.")
except Exception as e:
    logger.error(f"âŒ Failed to load global configurations: {e}")

# Socket.IO í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ë°±ì—”ë“œ ì„œë²„ì— ì—°ê²°)
sio_client = socketio.AsyncClient(logger=verbose, engineio_logger=verbose)

# --- Broadcaster ì „ìš© ìƒíƒœ ë° ìºì‹œ ê´€ë¦¬ ---

ticker_to_asset_id_cache: Dict[str, int] = {}
last_asset_cache_refresh: Optional[datetime] = None
asset_cache_refresh_interval = timedelta(minutes=10)

# REALTIME_STREAMS ì„¤ì •ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ê°’
default_streams = ["binance:realtime", "coinbase:realtime", "finnhub:realtime", "alpaca:realtime", "swissquote:realtime"]
stream_names = GLOBAL_APP_CONFIGS.get("REALTIME_STREAMS", default_streams)
realtime_streams = {
    stream: f"{stream.split(':')[0]}_broadcaster_group" for stream in stream_names
}



@sio_client.event
async def connect():
    logger.info("âœ… 'backend' ì„œë¹„ìŠ¤ì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")


@sio_client.event
async def disconnect():
    logger.warning("ğŸ”Œ 'backend' ì„œë¹„ìŠ¤ì™€ì˜ ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤.")


async def _refresh_asset_cache():
    """DBì—ì„œ Ticker -> Asset ID ë§µì„ ê°€ì ¸ì™€ ìºì‹œí•©ë‹ˆë‹¤."""
    global ticker_to_asset_id_cache, last_asset_cache_refresh
    logger.debug("ğŸ”„ Ticker-AssetID ìºì‹œ ê°±ì‹  ì‹œì‘...")
    from app.core.database import get_async_session_local
    from app.models.asset import Asset
    from sqlalchemy.future import select

    session_local = get_async_session_local()
    async with session_local() as session:
        try:
            result = await session.execute(select(Asset.ticker, Asset.asset_id))
            ticker_to_asset_id_cache = {ticker: asset_id for ticker, asset_id in result.all()}
            last_asset_cache_refresh = datetime.now(timezone.utc)
            logger.info(f"âœ… Ticker-AssetID ìºì‹œ ê°±ì‹  ì™„ë£Œ: {len(ticker_to_asset_id_cache)}ê°œ ìì‚°")
        except Exception as e:
            logger.error(f"âŒ Ticker-AssetID ìºì‹œ ê°±ì‹  ì‹¤íŒ¨: {e}")



async def listen_to_redis_and_broadcast():
    """Redis Streamì„ êµ¬ë…í•˜ê³  ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë°±ì—”ë“œë¡œ ì „ì†¡í•˜ëŠ” ë©”ì¸ ë¡œì§"""
    redis_host = GLOBAL_APP_CONFIGS.get("REDIS_HOST", "redis")
    redis_port = GLOBAL_APP_CONFIGS.get("REDIS_PORT", 6379)
    redis_db = GLOBAL_APP_CONFIGS.get("REDIS_DB", 0)
    redis_password = GLOBAL_APP_CONFIGS.get("REDIS_PASSWORD")
    # DB ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•˜ì—¬ URL êµ¬ì„± (producerë“¤ê³¼ ë™ì¼í•œ DB ì‚¬ìš© ë³´ì¥)
    try:
        redis_db_int = int(redis_db) if redis_db is not None else 0
    except Exception:
        redis_db_int = 0

    redis_url = f"redis://{redis_host}:{redis_port}/{redis_db_int}"
    if redis_password:
        redis_url = f"redis://:{redis_password}@{redis_host}:{redis_port}/{redis_db_int}"

    logger.info(f"ğŸ”— Redis Stream ë¦¬ìŠ¤ë„ˆ ì‹œì‘: {redis_url}")

    while True:
        logger.debug("[Broadcaster] Main loop tick - preparing to connect to Redis")
        redis_client = None
        try:
            logger.debug("[Broadcaster] Connecting to Redis...")
            redis_client = await redis.from_url(redis_url)
            logger.debug("[Broadcaster] Redis connected. Creating/ensuring consumer groups...")
            for stream_name, group_name in realtime_streams.items():
                logger.debug(f"[Broadcaster] Ensure group '{group_name}' on stream '{stream_name}'")
                try:
                    # ë¨¼ì € ìŠ¤íŠ¸ë¦¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                    stream_exists = await redis_client.exists(stream_name)
                    if not stream_exists:
                        logger.info(f"ğŸ“ ìŠ¤íŠ¸ë¦¼ '{stream_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ë¹ˆ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì¤‘...")
                        # ë¹ˆ ìŠ¤íŠ¸ë¦¼ ìƒì„± (ë”ë¯¸ ë°ì´í„°ë¡œ)
                        await redis_client.xadd(stream_name, {"init": "stream_created"}, maxlen=1, approximate=True)
                        logger.info(f"âœ… ë¹ˆ ìŠ¤íŠ¸ë¦¼ '{stream_name}' ìƒì„± ì™„ë£Œ")
                    
                    # Consumer Group ìƒì„±
                    await redis_client.xgroup_create(name=stream_name, groupname=group_name, id="0", mkstream=True)
                    logger.info(f"âœ… Consumer Group ìƒì„±: {group_name} on {stream_name}")
                except exceptions.ResponseError as e:
                    if "BUSYGROUP" in str(e):
                        logger.debug(f"â„¹ï¸ Consumer Group '{group_name}'ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                    else:
                        logger.error(f"Consumer Group '{group_name}' ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)

            logger.debug("[Broadcaster] Entering Redis read loop...")
            while True:
                # ì£¼ê¸°ì ìœ¼ë¡œ ìºì‹œ ê°±ì‹ 
                now = datetime.now(timezone.utc)
                if not last_asset_cache_refresh or (now - last_asset_cache_refresh) > asset_cache_refresh_interval:
                    logger.debug("[Broadcaster] Refreshing asset cache...")
                    await _refresh_asset_cache()

                # ê° ìŠ¤íŠ¸ë¦¼ì„ ìˆœíšŒí•˜ë©° ë°ì´í„° ì½ê¸°
                all_messages = []
                for stream_name, group_name in realtime_streams.items():
                    try:
                        # ìŠ¤íŠ¸ë¦¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                        stream_exists = await redis_client.exists(stream_name)
                        if not stream_exists:
                            logger.debug(f"ğŸ“­ ìŠ¤íŠ¸ë¦¼ '{stream_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ê±´ë„ˆëœ€")
                            continue
                            
                        logger.info(f"[Broadcaster] XREADGROUP from '{stream_name}' as '{group_name}'...")
                        # ê° ìŠ¤íŠ¸ë¦¼ì—ì„œ ê°œë³„ì ìœ¼ë¡œ ë°ì´í„° ì½ê¸°
                        stream_data = await redis_client.xreadgroup(
                            groupname=group_name,
                            consumername=f"consumer-{int(time.time())}",
                            streams={stream_name: ">"},
                            count=100,
                            block=10  # ì§§ì€ ë¸”ë¡œí‚¹ ì‹œê°„
                        )
                        logger.info(f"[Broadcaster] XREADGROUP result for '{stream_name}': {len(stream_data) if stream_data else 0} batches")
                        if stream_data:
                            for stream_name_bytes, messages in stream_data:
                                stream_name_str = stream_name_bytes.decode('utf-8') if isinstance(stream_name_bytes, bytes) else str(stream_name_bytes)
                                logger.info(f"ğŸ“¥ [BROADCASTERâ†REDIS] ìŠ¤íŠ¸ë¦¼ '{stream_name_str}'ì—ì„œ {len(messages)}ê°œ ë©”ì‹œì§€ ìˆ˜ì‹ ")
                                for message_id, message_data in messages:
                                    symbol = message_data.get(b'symbol', b'').decode('utf-8').upper()
                                    price = message_data.get(b'price', b'').decode('utf-8')
                                    logger.info(f"ğŸ“¥ [BROADCASTERâ†REDIS] ë©”ì‹œì§€ ì²˜ë¦¬: {symbol} = ${price}")
                        if stream_data:
                            # (stream_name, messages) íŠœí”Œì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                            all_messages.extend(stream_data)
                    except exceptions.ResponseError as e:
                        if "NOGROUP" in str(e):
                            logger.warning(f"âš ï¸ Consumer Group '{group_name}'ê°€ ìŠ¤íŠ¸ë¦¼ '{stream_name}'ì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ì¬ìƒì„± ì‹œë„...")
                            try:
                                await redis_client.xgroup_create(name=stream_name, groupname=group_name, id="0", mkstream=True)
                                logger.info(f"âœ… Consumer Group '{group_name}' ì¬ìƒì„± ì™„ë£Œ")
                            except Exception as recreate_error:
                                logger.error(f"âŒ Consumer Group ì¬ìƒì„± ì‹¤íŒ¨: {recreate_error}")
                        else:
                            logger.error(f"ìŠ¤íŠ¸ë¦¼ '{stream_name}' ì½ê¸° ì˜¤ë¥˜: {e}", exc_info=True)
                        continue

                for stream_name_bytes, messages in all_messages:
                    stream_name = stream_name_bytes.decode('utf-8') if isinstance(stream_name_bytes, bytes) else stream_name_bytes
                    group_name = realtime_streams.get(stream_name)

                    for message_id, message_data in messages:
                        try:
                            symbol = message_data.get(b'symbol', b'').decode('utf-8').upper()
                            price = safe_float(message_data.get(b'price', b'').decode('utf-8'))
                            volume = safe_float(message_data.get(b'volume', b'').decode('utf-8'))
                            provider = message_data.get(b'provider', b'unknown').decode('utf-8')

                            if not symbol or price is None:
                                continue

                            # ë¨¼ì € ì „ì²´ ì‹¬ë³¼ë¡œ ê²€ìƒ‰, ì—†ìœ¼ë©´ USDT ì ‘ë¯¸ì‚¬ ì œê±°í•˜ì—¬ ê²€ìƒ‰
                            asset_id = ticker_to_asset_id_cache.get(symbol)
                            if not asset_id and symbol.endswith('USDT'):
                                symbol_for_db = symbol.replace('USDT', '')
                                asset_id = ticker_to_asset_id_cache.get(symbol_for_db)
                                logger.debug(f"ğŸ” Full symbol '{symbol}' not found, trying without USDT: '{symbol_for_db}'")
                            
                            if not asset_id:
                                logger.warning(f"âš ï¸ Asset ID not found for symbol: {symbol}")
                                logger.warning(f"ğŸ“‹ Available symbols in cache: {list(ticker_to_asset_id_cache.keys())[:10]}...")
                                continue
                            else:
                                logger.debug(f"âœ… Found asset_id {asset_id} for symbol: {symbol}")

                            quote_data = {
                                "asset_id": asset_id,
                                "ticker": symbol,
                                "timestamp_utc": datetime.now(timezone.utc).isoformat(),
                                "price": price,
                                "volume": volume,
                                "data_source": provider
                            }

                            if sio_client.connected:
                                logger.info(f"ğŸ“¤ [BROADCASTERâ†’BACKEND] ì „ì†¡ ì‹œë„: {symbol} = ${price} (asset_id: {asset_id})")
                                await sio_client.emit('broadcast_quote', quote_data)
                                logger.info(f"âœ… [BROADCASTERâ†’BACKEND] ì „ì†¡ ì™„ë£Œ: {symbol} = ${price}")
                            else:
                                logger.warning(f"âš ï¸ [BROADCASTERâ†’BACKEND] ë°±ì—”ë“œ ì—°ê²° ì‹¤íŒ¨: {symbol} ì „ì†¡ ë¶ˆê°€")

                            # ë©”ì‹œì§€ ACK
                            await redis_client.xack(stream_name, group_name, message_id)

                        except Exception as e:
                            logger.exception(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ACK ì²˜ë¦¬í•˜ì—¬ ë¬´í•œ ë£¨í”„ ë°©ì§€
                            await redis_client.xack(stream_name, group_name, message_id)

        except asyncio.CancelledError:
            logger.info("ğŸ›‘ Redis listener task was cancelled.")
            raise
        except (exceptions.ConnectionError, exceptions.TimeoutError) as e:
            logger.exception(f"âŒ Redis Stream ì—°ê²° ì˜¤ë¥˜: {e}")
        except Exception as e:
            logger.exception(f"âŒ Redis ë¦¬ìŠ¤ë„ˆ ë£¨í”„ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
        finally:
            logger.error("ğŸ”Œ Redis ì—°ê²° ì •ë¦¬ ë° 5ì´ˆ í›„ ì¬ì‹œë„...")
            if redis_client:
                try:
                    await redis_client.close()
                except Exception as redis_err:
                    logger.exception(f"Redis í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {redis_err}")
            await asyncio.sleep(5)


async def main():
    """ì„œë¹„ìŠ¤ ì‹œì‘ì """
    backend_url = "http://backend:8000"  # Docker ë„¤íŠ¸ì›Œí¬ ë‚´ë¶€ í†µì‹ 

    # ë°±ì—”ë“œì— ì—°ê²° ì‹œë„
    while not sio_client.connected:
        try:
            await sio_client.connect(backend_url, transports=["websocket"])
        except Exception as e:
            logger.critical(f"âŒ ë°±ì—”ë“œ({backend_url})ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 5ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
            await asyncio.sleep(5)

    # Redis ë¦¬ìŠ¤ë„ˆ ì‹œì‘
    listener_task = asyncio.create_task(listen_to_redis_and_broadcast())

    def _signal_handler(*_):
        logger.info("SIGINT ë˜ëŠ” SIGTERM ìˆ˜ì‹ , ì¢…ë£Œí•©ë‹ˆë‹¤...")
        # íƒœìŠ¤í¬ë¥¼ ì§ì ‘ ì·¨ì†Œ
        if not listener_task.done():
            listener_task.cancel()

    loop = asyncio.get_running_loop()
    loop.add_signal_handler(signal.SIGINT, _signal_handler)
    loop.add_signal_handler(signal.SIGTERM, _signal_handler)

    try:
        # íƒœìŠ¤í¬ê°€ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        await listener_task
    except asyncio.CancelledError:
        logger.info("Listener task successfully cancelled.")
    finally:
        # ì •ë¦¬
        if sio_client.connected:
            await sio_client.disconnect()
        logger.info("ğŸ‘‹ Broadcaster ì„œë¹„ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())
